{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # Lecture 13: Training deep neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 2020-03-21 19:04:51\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(\"Version: \" + now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vanishing and exploding gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Training typically relies on gradients.\n",
    "\n",
    "*Vanishing gradients problem*: For deep networks, gradients in lower layers can become very small.  Hence, corresponding weights are not updated during training.\n",
    "\n",
    "*Exploding gradients problem*: In some situations (typically recurrent neural networks) gradients can become very large.  Hence, weight updates are very large and the training algorithm may not converge.\n",
    "\n",
    "In general deep neural networks can suffer from *unstable gradients*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problematic activation functions\n",
    "\n",
    "One common cause of vanishing gradients in the past was the use of the sigmoid activation function (and unit Gaussian initialisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, 5, -0.2, 1.2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    " \n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Variance of outputs grows at each layer.  Final layers essentially saturate.  Gradients on final layers then very small and when propagate gradients back with back-propagation then get vanishing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Weight initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "To avoid this problem need signals and gradents to *not* decay as propagating through network.\n",
    "\n",
    "Avoid decaying signals/gradients by promoting equal variance at outputs and inputs of layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can be promoted by random initialisation of weights to follow Gaussian with standard deviation:\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\text{Sigmoid activation:} \\quad\\quad & \\sigma = \\sqrt{\\frac{2}{n_{\\rm inputs}+n_{\\rm outputs}}} \\\\\n",
    "\\text{Hyperbolic tangent activation:} \\quad\\quad & \\sigma = 4\\sqrt{\\frac{2}{n_{\\rm inputs}+n_{\\rm outputs}}} \\\\\n",
    "\\text{ReLU activation:} \\quad\\quad & \\sigma = \\sqrt{2}\\sqrt{\\frac{2}{n_{\\rm inputs}+n_{\\rm outputs}}} \\\\\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "where $n_{\\rm inputs}$ and $n_{\\rm outputs}$ are the number of input and output nodes, respectively, for the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Weight initialisation in Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-7-c75b27a27319>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6d7410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6d7410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6d7410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6d7410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                          kernel_initializer=he_init, name=\"hidden1\") # He initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Non-saturating activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "ReLU activation behaves much better than the sigmoid in deep networks since it does not saturate for positive values (and it is fast to compute)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, the ReLU does suffer from the *dying neuron* problem.\n",
    "\n",
    "In this senario neurons effectively die and only output zero.  The neuron is unlikely to come back to life since the gradient of the ReLU activation function is zero for negative inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Leaky ReLU\n",
    "\n",
    "The *leaky ReLU* avoids this problem and is defined by\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}_\\alpha(z) = \\max(\\alpha z, z),\n",
    "$$\n",
    "\n",
    "where the hyperparameter $\\alpha$ defines how much the leaky ReLU leaks (typically $\\alpha=0.01$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### Exercise: plot the Leaky ReLU activation function for $\\alpha=0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "exercise",
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "exercise",
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, 5, -0.5, 4.2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ELU\n",
    "\n",
    "Another alternative is the *exponental linear unit* (ELU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### Exercise: plot the ELU activation function for $\\alpha=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "exercise",
     "solution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, 5, -2.2, 3.2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Properties:\n",
    "- Non-zero gradient for $z<0$ to avoid dying neuron issue.\n",
    "- Smooth so gradients well defined.\n",
    "- But is slower to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ELU in Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ed11f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ed11f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ed11f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ed11f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Batch normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "While weight normalisation can reduce gradient problems at the beginning of training, it does not guarantee that these problems won't resurface during training.\n",
    "\n",
    "*Batch normalisation* adds normalisation during training to address these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Consists of zero-centering and normalising inputs just before the activation function, followed by shifting and scaling the result.  The shift and scale are considered additional parameters that are learnt during training.\n",
    "\n",
    "This approach allows training to select the appropriate scale and shift (mean) for each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The mean and standard deviation of the unnormalised inputs are computed for each mini-batch, hence the name *batch normalisation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When the trained network is applied to the test set there are no batches, so instead the entire *training* set's mean and standard deviation are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Batch normalisation in Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ec22250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ec22250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ec22250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ec22250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-14-9b2a8c010cf1>:16: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13eced690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13eced690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13eced690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13eced690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13eced690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13eced690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13eced690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13eced690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13ed11c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13ed11c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13ed11c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13ed11c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ef4ad10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ef4ad10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ef4ad10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ef4ad10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13efa7c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13efa7c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13efa7c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13efa7c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, \n",
    "                                    training=training, momentum=0.9) \n",
    "    # Exponential decay is applied when computing running averages, hence the momentum parameter.\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Python `partial` function can be handy for defining a new function with some arguments set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ec0c5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ec0c5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ec0c5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ec0c5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13c71aa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13c71aa90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13c71aa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13c71aa90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c71aa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c71aa90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c71aa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c71aa90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13c6b90d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13c6b90d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13c6b90d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13c6b90d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6b90d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6b90d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6b90d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6b90d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13a134e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13a134e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13a134e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13a134e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                              training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "## Exercise: build a deep NN with ELU activation functions and batch normalisation and apply it to MINST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "exercise"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-c50d5bb4a85c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "exercise",
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6d7290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6d7290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6d7290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13c6d7290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13a134750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13a134750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13a134750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13a134750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ed09d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ed09d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ed09d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13ed09d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13ed09d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13ed09d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13ed09d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13ed09d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13f253890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13f253890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13f253890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x13f253890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13f253890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13f253890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13f253890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x13f253890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "exercise",
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "exercise",
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.8653\n",
      "1 Test accuracy: 0.8939\n",
      "2 Test accuracy: 0.9086\n",
      "3 Test accuracy: 0.9199\n",
      "4 Test accuracy: 0.9258\n",
      "5 Test accuracy: 0.9328\n",
      "6 Test accuracy: 0.9379\n",
      "7 Test accuracy: 0.9429\n",
      "8 Test accuracy: 0.9448\n",
      "9 Test accuracy: 0.9478\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) # add moving average updates to computational graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "exercise",
     "solution"
    ]
   },
   "source": [
    "Performance will get better if train for longer.  In any case, ELU and batch normalisation not likely to really help with such a shallow network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pretraining and transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A deep network trained for one task can often be adapted for a similar task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reuse lower layers of network trained for another task.\n",
    "\n",
    "<center><img src=\"Lecture13_Images/transfer_learning.png\" style=\"height: 350px;\"/></center>\n",
    "\n",
    "[Credit: Geron]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For transfer learning to be successful the data must have similar low-level features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Reusing a Tensor Flow model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "As we saw in previous lectures we can save and load computational graphs in addition to parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The computation graph is saved in `*.meta` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "y\n",
      "training/input\n",
      "training\n",
      "hidden1/kernel/Initializer/truncated_normal/shape\n",
      "hidden1/kernel/Initializer/truncated_normal/mean\n",
      "hidden1/kernel/Initializer/truncated_normal/stddev\n",
      "hidden1/kernel/Initializer/truncated_normal/TruncatedNormal\n",
      "hidden1/kernel/Initializer/truncated_normal/mul\n",
      "hidden1/kernel/Initializer/truncated_normal\n",
      "hidden1/kernel\n",
      "hidden1/kernel/Assign\n",
      "hidden1/kernel/read\n",
      "hidden1/bias/Initializer/zeros\n",
      "hidden1/bias\n",
      "hidden1/bias/Assign\n",
      "hidden1/bias/read\n",
      "dnn/hidden1/MatMul\n",
      "dnn/hidden1/BiasAdd\n",
      "batch_normalization/gamma/Initializer/ones\n",
      "batch_normalization/gamma\n",
      "batch_normalization/gamma/Assign\n",
      "batch_normalization/gamma/read\n",
      "batch_normalization/beta/Initializer/zeros\n",
      "batch_normalization/beta\n",
      "batch_normalization/beta/Assign\n",
      "batch_normalization/beta/read\n",
      "batch_normalization/moving_mean/Initializer/zeros\n",
      "batch_normalization/moving_mean\n",
      "batch_normalization/moving_mean/Assign\n",
      "batch_normalization/moving_mean/read\n",
      "batch_normalization/moving_variance/Initializer/ones\n",
      "batch_normalization/moving_variance\n",
      "batch_normalization/moving_variance/Assign\n",
      "batch_normalization/moving_variance/read\n",
      "dnn/batch_normalization/moments/mean/reduction_indices\n",
      "dnn/batch_normalization/moments/mean\n",
      "dnn/batch_normalization/moments/StopGradient\n",
      "dnn/batch_normalization/moments/SquaredDifference\n",
      "dnn/batch_normalization/moments/variance/reduction_indices\n",
      "dnn/batch_normalization/moments/variance\n",
      "dnn/batch_normalization/moments/Squeeze\n",
      "dnn/batch_normalization/moments/Squeeze_1\n",
      "dnn/batch_normalization/cond/Switch\n",
      "dnn/batch_normalization/cond/switch_t\n",
      "dnn/batch_normalization/cond/switch_f\n",
      "dnn/batch_normalization/cond/pred_id\n",
      "dnn/batch_normalization/cond/Switch_1\n",
      "dnn/batch_normalization/cond/Switch_2\n",
      "dnn/batch_normalization/cond/Merge\n",
      "dnn/batch_normalization/cond_1/Switch\n",
      "dnn/batch_normalization/cond_1/switch_t\n",
      "dnn/batch_normalization/cond_1/switch_f\n",
      "dnn/batch_normalization/cond_1/pred_id\n",
      "dnn/batch_normalization/cond_1/Switch_1\n",
      "dnn/batch_normalization/cond_1/Switch_2\n",
      "dnn/batch_normalization/cond_1/Merge\n",
      "dnn/batch_normalization/cond_2/Switch\n",
      "dnn/batch_normalization/cond_2/switch_t\n",
      "dnn/batch_normalization/cond_2/switch_f\n",
      "dnn/batch_normalization/cond_2/pred_id\n",
      "dnn/batch_normalization/cond_2/AssignMovingAvg/decay\n",
      "dnn/batch_normalization/cond_2/AssignMovingAvg/sub/Switch\n",
      "dnn/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1\n",
      "dnn/batch_normalization/cond_2/AssignMovingAvg/sub\n",
      "dnn/batch_normalization/cond_2/AssignMovingAvg/mul\n",
      "dnn/batch_normalization/cond_2/AssignMovingAvg/Switch\n",
      "dnn/batch_normalization/cond_2/AssignMovingAvg\n",
      "dnn/batch_normalization/cond_2/Switch_1\n",
      "dnn/batch_normalization/cond_2/Merge\n",
      "dnn/batch_normalization/cond_3/Switch\n",
      "dnn/batch_normalization/cond_3/switch_t\n",
      "dnn/batch_normalization/cond_3/switch_f\n",
      "dnn/batch_normalization/cond_3/pred_id\n",
      "dnn/batch_normalization/cond_3/AssignMovingAvg/decay\n",
      "dnn/batch_normalization/cond_3/AssignMovingAvg/sub/Switch\n",
      "dnn/batch_normalization/cond_3/AssignMovingAvg/sub/Switch_1\n",
      "dnn/batch_normalization/cond_3/AssignMovingAvg/sub\n",
      "dnn/batch_normalization/cond_3/AssignMovingAvg/mul\n",
      "dnn/batch_normalization/cond_3/AssignMovingAvg/Switch\n",
      "dnn/batch_normalization/cond_3/AssignMovingAvg\n",
      "dnn/batch_normalization/cond_3/Switch_1\n",
      "dnn/batch_normalization/cond_3/Merge\n",
      "dnn/batch_normalization/batchnorm/add/y\n",
      "dnn/batch_normalization/batchnorm/add\n",
      "dnn/batch_normalization/batchnorm/Rsqrt\n",
      "dnn/batch_normalization/batchnorm/mul\n",
      "dnn/batch_normalization/batchnorm/mul_1\n",
      "dnn/batch_normalization/batchnorm/mul_2\n",
      "dnn/batch_normalization/batchnorm/sub\n",
      "dnn/batch_normalization/batchnorm/add_1\n",
      "dnn/Elu\n",
      "hidden2/kernel/Initializer/truncated_normal/shape\n",
      "hidden2/kernel/Initializer/truncated_normal/mean\n",
      "hidden2/kernel/Initializer/truncated_normal/stddev\n",
      "hidden2/kernel/Initializer/truncated_normal/TruncatedNormal\n",
      "hidden2/kernel/Initializer/truncated_normal/mul\n",
      "hidden2/kernel/Initializer/truncated_normal\n",
      "hidden2/kernel\n",
      "hidden2/kernel/Assign\n",
      "hidden2/kernel/read\n",
      "hidden2/bias/Initializer/zeros\n",
      "hidden2/bias\n",
      "hidden2/bias/Assign\n",
      "hidden2/bias/read\n",
      "dnn/hidden2/MatMul\n",
      "dnn/hidden2/BiasAdd\n",
      "batch_normalization_1/gamma/Initializer/ones\n",
      "batch_normalization_1/gamma\n",
      "batch_normalization_1/gamma/Assign\n",
      "batch_normalization_1/gamma/read\n",
      "batch_normalization_1/beta/Initializer/zeros\n",
      "batch_normalization_1/beta\n",
      "batch_normalization_1/beta/Assign\n",
      "batch_normalization_1/beta/read\n",
      "batch_normalization_1/moving_mean/Initializer/zeros\n",
      "batch_normalization_1/moving_mean\n",
      "batch_normalization_1/moving_mean/Assign\n",
      "batch_normalization_1/moving_mean/read\n",
      "batch_normalization_1/moving_variance/Initializer/ones\n",
      "batch_normalization_1/moving_variance\n",
      "batch_normalization_1/moving_variance/Assign\n",
      "batch_normalization_1/moving_variance/read\n",
      "dnn/batch_normalization_1/moments/mean/reduction_indices\n",
      "dnn/batch_normalization_1/moments/mean\n",
      "dnn/batch_normalization_1/moments/StopGradient\n",
      "dnn/batch_normalization_1/moments/SquaredDifference\n",
      "dnn/batch_normalization_1/moments/variance/reduction_indices\n",
      "dnn/batch_normalization_1/moments/variance\n",
      "dnn/batch_normalization_1/moments/Squeeze\n",
      "dnn/batch_normalization_1/moments/Squeeze_1\n",
      "dnn/batch_normalization_1/cond/Switch\n",
      "dnn/batch_normalization_1/cond/switch_t\n",
      "dnn/batch_normalization_1/cond/switch_f\n",
      "dnn/batch_normalization_1/cond/pred_id\n",
      "dnn/batch_normalization_1/cond/Switch_1\n",
      "dnn/batch_normalization_1/cond/Switch_2\n",
      "dnn/batch_normalization_1/cond/Merge\n",
      "dnn/batch_normalization_1/cond_1/Switch\n",
      "dnn/batch_normalization_1/cond_1/switch_t\n",
      "dnn/batch_normalization_1/cond_1/switch_f\n",
      "dnn/batch_normalization_1/cond_1/pred_id\n",
      "dnn/batch_normalization_1/cond_1/Switch_1\n",
      "dnn/batch_normalization_1/cond_1/Switch_2\n",
      "dnn/batch_normalization_1/cond_1/Merge\n",
      "dnn/batch_normalization_1/cond_2/Switch\n",
      "dnn/batch_normalization_1/cond_2/switch_t\n",
      "dnn/batch_normalization_1/cond_2/switch_f\n",
      "dnn/batch_normalization_1/cond_2/pred_id\n",
      "dnn/batch_normalization_1/cond_2/AssignMovingAvg/decay\n",
      "dnn/batch_normalization_1/cond_2/AssignMovingAvg/sub/Switch\n",
      "dnn/batch_normalization_1/cond_2/AssignMovingAvg/sub/Switch_1\n",
      "dnn/batch_normalization_1/cond_2/AssignMovingAvg/sub\n",
      "dnn/batch_normalization_1/cond_2/AssignMovingAvg/mul\n",
      "dnn/batch_normalization_1/cond_2/AssignMovingAvg/Switch\n",
      "dnn/batch_normalization_1/cond_2/AssignMovingAvg\n",
      "dnn/batch_normalization_1/cond_2/Switch_1\n",
      "dnn/batch_normalization_1/cond_2/Merge\n",
      "dnn/batch_normalization_1/cond_3/Switch\n",
      "dnn/batch_normalization_1/cond_3/switch_t\n",
      "dnn/batch_normalization_1/cond_3/switch_f\n",
      "dnn/batch_normalization_1/cond_3/pred_id\n",
      "dnn/batch_normalization_1/cond_3/AssignMovingAvg/decay\n",
      "dnn/batch_normalization_1/cond_3/AssignMovingAvg/sub/Switch\n",
      "dnn/batch_normalization_1/cond_3/AssignMovingAvg/sub/Switch_1\n",
      "dnn/batch_normalization_1/cond_3/AssignMovingAvg/sub\n",
      "dnn/batch_normalization_1/cond_3/AssignMovingAvg/mul\n",
      "dnn/batch_normalization_1/cond_3/AssignMovingAvg/Switch\n",
      "dnn/batch_normalization_1/cond_3/AssignMovingAvg\n",
      "dnn/batch_normalization_1/cond_3/Switch_1\n",
      "dnn/batch_normalization_1/cond_3/Merge\n",
      "dnn/batch_normalization_1/batchnorm/add/y\n",
      "dnn/batch_normalization_1/batchnorm/add\n",
      "dnn/batch_normalization_1/batchnorm/Rsqrt\n",
      "dnn/batch_normalization_1/batchnorm/mul\n",
      "dnn/batch_normalization_1/batchnorm/mul_1\n",
      "dnn/batch_normalization_1/batchnorm/mul_2\n",
      "dnn/batch_normalization_1/batchnorm/sub\n",
      "dnn/batch_normalization_1/batchnorm/add_1\n",
      "dnn/Elu_1\n",
      "outputs/kernel/Initializer/truncated_normal/shape\n",
      "outputs/kernel/Initializer/truncated_normal/mean\n",
      "outputs/kernel/Initializer/truncated_normal/stddev\n",
      "outputs/kernel/Initializer/truncated_normal/TruncatedNormal\n",
      "outputs/kernel/Initializer/truncated_normal/mul\n",
      "outputs/kernel/Initializer/truncated_normal\n",
      "outputs/kernel\n",
      "outputs/kernel/Assign\n",
      "outputs/kernel/read\n",
      "outputs/bias/Initializer/zeros\n",
      "outputs/bias\n",
      "outputs/bias/Assign\n",
      "outputs/bias/read\n",
      "dnn/outputs/MatMul\n",
      "dnn/outputs/BiasAdd\n",
      "batch_normalization_2/gamma/Initializer/ones\n",
      "batch_normalization_2/gamma\n",
      "batch_normalization_2/gamma/Assign\n",
      "batch_normalization_2/gamma/read\n",
      "batch_normalization_2/beta/Initializer/zeros\n",
      "batch_normalization_2/beta\n",
      "batch_normalization_2/beta/Assign\n",
      "batch_normalization_2/beta/read\n",
      "batch_normalization_2/moving_mean/Initializer/zeros\n",
      "batch_normalization_2/moving_mean\n",
      "batch_normalization_2/moving_mean/Assign\n",
      "batch_normalization_2/moving_mean/read\n",
      "batch_normalization_2/moving_variance/Initializer/ones\n",
      "batch_normalization_2/moving_variance\n",
      "batch_normalization_2/moving_variance/Assign\n",
      "batch_normalization_2/moving_variance/read\n",
      "dnn/batch_normalization_2/moments/mean/reduction_indices\n",
      "dnn/batch_normalization_2/moments/mean\n",
      "dnn/batch_normalization_2/moments/StopGradient\n",
      "dnn/batch_normalization_2/moments/SquaredDifference\n",
      "dnn/batch_normalization_2/moments/variance/reduction_indices\n",
      "dnn/batch_normalization_2/moments/variance\n",
      "dnn/batch_normalization_2/moments/Squeeze\n",
      "dnn/batch_normalization_2/moments/Squeeze_1\n",
      "dnn/batch_normalization_2/cond/Switch\n",
      "dnn/batch_normalization_2/cond/switch_t\n",
      "dnn/batch_normalization_2/cond/switch_f\n",
      "dnn/batch_normalization_2/cond/pred_id\n",
      "dnn/batch_normalization_2/cond/Switch_1\n",
      "dnn/batch_normalization_2/cond/Switch_2\n",
      "dnn/batch_normalization_2/cond/Merge\n",
      "dnn/batch_normalization_2/cond_1/Switch\n",
      "dnn/batch_normalization_2/cond_1/switch_t\n",
      "dnn/batch_normalization_2/cond_1/switch_f\n",
      "dnn/batch_normalization_2/cond_1/pred_id\n",
      "dnn/batch_normalization_2/cond_1/Switch_1\n",
      "dnn/batch_normalization_2/cond_1/Switch_2\n",
      "dnn/batch_normalization_2/cond_1/Merge\n",
      "dnn/batch_normalization_2/cond_2/Switch\n",
      "dnn/batch_normalization_2/cond_2/switch_t\n",
      "dnn/batch_normalization_2/cond_2/switch_f\n",
      "dnn/batch_normalization_2/cond_2/pred_id\n",
      "dnn/batch_normalization_2/cond_2/AssignMovingAvg/decay\n",
      "dnn/batch_normalization_2/cond_2/AssignMovingAvg/sub/Switch\n",
      "dnn/batch_normalization_2/cond_2/AssignMovingAvg/sub/Switch_1\n",
      "dnn/batch_normalization_2/cond_2/AssignMovingAvg/sub\n",
      "dnn/batch_normalization_2/cond_2/AssignMovingAvg/mul\n",
      "dnn/batch_normalization_2/cond_2/AssignMovingAvg/Switch\n",
      "dnn/batch_normalization_2/cond_2/AssignMovingAvg\n",
      "dnn/batch_normalization_2/cond_2/Switch_1\n",
      "dnn/batch_normalization_2/cond_2/Merge\n",
      "dnn/batch_normalization_2/cond_3/Switch\n",
      "dnn/batch_normalization_2/cond_3/switch_t\n",
      "dnn/batch_normalization_2/cond_3/switch_f\n",
      "dnn/batch_normalization_2/cond_3/pred_id\n",
      "dnn/batch_normalization_2/cond_3/AssignMovingAvg/decay\n",
      "dnn/batch_normalization_2/cond_3/AssignMovingAvg/sub/Switch\n",
      "dnn/batch_normalization_2/cond_3/AssignMovingAvg/sub/Switch_1\n",
      "dnn/batch_normalization_2/cond_3/AssignMovingAvg/sub\n",
      "dnn/batch_normalization_2/cond_3/AssignMovingAvg/mul\n",
      "dnn/batch_normalization_2/cond_3/AssignMovingAvg/Switch\n",
      "dnn/batch_normalization_2/cond_3/AssignMovingAvg\n",
      "dnn/batch_normalization_2/cond_3/Switch_1\n",
      "dnn/batch_normalization_2/cond_3/Merge\n",
      "dnn/batch_normalization_2/batchnorm/add/y\n",
      "dnn/batch_normalization_2/batchnorm/add\n",
      "dnn/batch_normalization_2/batchnorm/Rsqrt\n",
      "dnn/batch_normalization_2/batchnorm/mul\n",
      "dnn/batch_normalization_2/batchnorm/mul_1\n",
      "dnn/batch_normalization_2/batchnorm/mul_2\n",
      "dnn/batch_normalization_2/batchnorm/sub\n",
      "dnn/batch_normalization_2/batchnorm/add_1\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n",
      "loss/Const\n",
      "loss/loss\n",
      "train/gradients/Shape\n",
      "train/gradients/grad_ys_0\n",
      "train/gradients/Fill\n",
      "train/gradients/loss/loss_grad/Reshape/shape\n",
      "train/gradients/loss/loss_grad/Reshape\n",
      "train/gradients/loss/loss_grad/Shape\n",
      "train/gradients/loss/loss_grad/Tile\n",
      "train/gradients/loss/loss_grad/Shape_1\n",
      "train/gradients/loss/loss_grad/Shape_2\n",
      "train/gradients/loss/loss_grad/Const\n",
      "train/gradients/loss/loss_grad/Prod\n",
      "train/gradients/loss/loss_grad/Const_1\n",
      "train/gradients/loss/loss_grad/Prod_1\n",
      "train/gradients/loss/loss_grad/Maximum/y\n",
      "train/gradients/loss/loss_grad/Maximum\n",
      "train/gradients/loss/loss_grad/floordiv\n",
      "train/gradients/loss/loss_grad/Cast\n",
      "train/gradients/loss/loss_grad/truediv\n",
      "train/gradients/zeros_like\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_1_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_1_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_1_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_1_grad/Sum\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_1_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_1_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_1_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_1_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_1_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_1_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/Mul\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/Sum\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/Mul_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_1_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/sub_grad/Neg\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/sub_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/sub_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/sub_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_2_grad/Mul\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_2_grad/Mul_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_2_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_2_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_2_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_2/cond/Merge_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization_2/cond/Merge_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_2/cond/Merge_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_2/cond/Merge_grad/tuple/control_dependency_1\n",
      "train/gradients/AddN\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_grad/Mul\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_grad/Mul_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/mul_grad/tuple/control_dependency_1\n",
      "train/gradients/Switch\n",
      "train/gradients/Identity\n",
      "train/gradients/Shape_1\n",
      "train/gradients/zeros/Const\n",
      "train/gradients/zeros\n",
      "train/gradients/dnn/batch_normalization_2/cond/Switch_1_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/Rsqrt_grad/RsqrtGrad\n",
      "train/gradients/dnn/batch_normalization_2/moments/Squeeze_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_2/moments/Squeeze_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_grad/Sum\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_2/batchnorm/add_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_2/cond_1/Merge_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization_2/cond_1/Merge_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_2/cond_1/Merge_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_2/cond_1/Merge_grad/tuple/control_dependency_1\n",
      "train/gradients/Switch_1\n",
      "train/gradients/Identity_1\n",
      "train/gradients/Shape_2\n",
      "train/gradients/zeros_1/Const\n",
      "train/gradients/zeros_1\n",
      "train/gradients/dnn/batch_normalization_2/cond_1/Switch_1_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization_2/moments/Squeeze_1_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_2/moments/Squeeze_1_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Size\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/add\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/mod\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/range/start\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/range/delta\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/range\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Fill/value\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Fill\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/DynamicStitch\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Maximum/y\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Maximum\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/floordiv\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Tile\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Shape_2\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Shape_3\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Const\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Prod\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Const_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Prod_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Maximum_1/y\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Maximum_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/floordiv_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/Cast\n",
      "train/gradients/dnn/batch_normalization_2/moments/variance_grad/truediv\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/scalar\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/Mul\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/sub\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/mul_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/Sum\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/Neg\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_2/moments/SquaredDifference_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Size\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/add\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/mod\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/range/start\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/range/delta\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/range\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Fill/value\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Fill\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/DynamicStitch\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Maximum/y\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Maximum\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/floordiv\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Tile\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Shape_2\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Shape_3\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Const\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Prod\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Const_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Prod_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Maximum_1/y\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Maximum_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/floordiv_1\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/Cast\n",
      "train/gradients/dnn/batch_normalization_2/moments/mean_grad/truediv\n",
      "train/gradients/AddN_1\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "train/gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/Elu_1_grad/EluGrad\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_1_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_1_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_1_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_1_grad/Sum\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_1_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_1_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_1_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_1_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_1_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_1_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/Mul\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/Sum\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/Mul_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_1_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/sub_grad/Neg\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/sub_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/sub_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/sub_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_2_grad/Mul\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_2_grad/Mul_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_2_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_2_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_2_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_1/cond/Merge_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization_1/cond/Merge_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_1/cond/Merge_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_1/cond/Merge_grad/tuple/control_dependency_1\n",
      "train/gradients/AddN_2\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_grad/Mul\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_grad/Mul_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/mul_grad/tuple/control_dependency_1\n",
      "train/gradients/Switch_2\n",
      "train/gradients/Identity_2\n",
      "train/gradients/Shape_3\n",
      "train/gradients/zeros_2/Const\n",
      "train/gradients/zeros_2\n",
      "train/gradients/dnn/batch_normalization_1/cond/Switch_1_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/Rsqrt_grad/RsqrtGrad\n",
      "train/gradients/dnn/batch_normalization_1/moments/Squeeze_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_1/moments/Squeeze_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_grad/Sum\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_1/batchnorm/add_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_1/cond_1/Merge_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization_1/cond_1/Merge_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_1/cond_1/Merge_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_1/cond_1/Merge_grad/tuple/control_dependency_1\n",
      "train/gradients/Switch_3\n",
      "train/gradients/Identity_3\n",
      "train/gradients/Shape_4\n",
      "train/gradients/zeros_3/Const\n",
      "train/gradients/zeros_3\n",
      "train/gradients/dnn/batch_normalization_1/cond_1/Switch_1_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization_1/moments/Squeeze_1_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_1/moments/Squeeze_1_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Size\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/add\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/mod\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/range/start\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/range/delta\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/range\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Fill/value\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Fill\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/DynamicStitch\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Maximum/y\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Maximum\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/floordiv\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Tile\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Shape_2\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Shape_3\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Const\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Prod\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Const_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Prod_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Maximum_1/y\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Maximum_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/floordiv_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/Cast\n",
      "train/gradients/dnn/batch_normalization_1/moments/variance_grad/truediv\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/scalar\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/Mul\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/sub\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/mul_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/Sum\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/Neg\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization_1/moments/SquaredDifference_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Shape\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Size\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/add\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/mod\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/range/start\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/range/delta\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/range\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Fill/value\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Fill\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/DynamicStitch\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Maximum/y\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Maximum\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/floordiv\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Tile\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Shape_2\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Shape_3\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Const\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Prod\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Const_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Prod_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Maximum_1/y\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Maximum_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/floordiv_1\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/Cast\n",
      "train/gradients/dnn/batch_normalization_1/moments/mean_grad/truediv\n",
      "train/gradients/AddN_3\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "train/gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/Elu_grad/EluGrad\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_1_grad/Shape\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_1_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_1_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_1_grad/Sum\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_1_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_1_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_1_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_1_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_1_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/Shape\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/Mul\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/Sum\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/Mul_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_1_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/sub_grad/Neg\n",
      "train/gradients/dnn/batch_normalization/batchnorm/sub_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization/batchnorm/sub_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization/batchnorm/sub_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_2_grad/Mul\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_2_grad/Mul_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_2_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_2_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization/cond/Merge_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization/cond/Merge_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization/cond/Merge_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization/cond/Merge_grad/tuple/control_dependency_1\n",
      "train/gradients/AddN_4\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_grad/Mul\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_grad/Mul_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization/batchnorm/mul_grad/tuple/control_dependency_1\n",
      "train/gradients/Switch_4\n",
      "train/gradients/Identity_4\n",
      "train/gradients/Shape_5\n",
      "train/gradients/zeros_4/Const\n",
      "train/gradients/zeros_4\n",
      "train/gradients/dnn/batch_normalization/cond/Switch_1_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization/batchnorm/Rsqrt_grad/RsqrtGrad\n",
      "train/gradients/dnn/batch_normalization/moments/Squeeze_grad/Shape\n",
      "train/gradients/dnn/batch_normalization/moments/Squeeze_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_grad/Shape\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_grad/Sum\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization/batchnorm/add_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization/cond_1/Merge_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization/cond_1/Merge_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization/cond_1/Merge_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization/cond_1/Merge_grad/tuple/control_dependency_1\n",
      "train/gradients/Switch_5\n",
      "train/gradients/Identity_5\n",
      "train/gradients/Shape_6\n",
      "train/gradients/zeros_5/Const\n",
      "train/gradients/zeros_5\n",
      "train/gradients/dnn/batch_normalization/cond_1/Switch_1_grad/cond_grad\n",
      "train/gradients/dnn/batch_normalization/moments/Squeeze_1_grad/Shape\n",
      "train/gradients/dnn/batch_normalization/moments/Squeeze_1_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Shape\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Size\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/add\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/mod\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/range/start\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/range/delta\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/range\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Fill/value\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Fill\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/DynamicStitch\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Maximum/y\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Maximum\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/floordiv\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Tile\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Shape_2\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Shape_3\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Const\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Prod\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Const_1\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Prod_1\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Maximum_1/y\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Maximum_1\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/floordiv_1\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/Cast\n",
      "train/gradients/dnn/batch_normalization/moments/variance_grad/truediv\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/Shape\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/scalar\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/Mul\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/sub\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/mul_1\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/Sum\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/Sum_1\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/Reshape_1\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/Neg\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/tuple/group_deps\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency\n",
      "train/gradients/dnn/batch_normalization/moments/SquaredDifference_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Shape\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Size\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/add\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/mod\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Shape_1\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/range/start\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/range/delta\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/range\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Fill/value\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Fill\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/DynamicStitch\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Maximum/y\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Maximum\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/floordiv\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Reshape\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Tile\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Shape_2\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Shape_3\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Const\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Prod\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Const_1\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Prod_1\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Maximum_1/y\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Maximum_1\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/floordiv_1\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/Cast\n",
      "train/gradients/dnn/batch_normalization/moments/mean_grad/truediv\n",
      "train/gradients/AddN_5\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "train/gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "train/GradientDescent/learning_rate\n",
      "train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "train/GradientDescent/update_batch_normalization/gamma/ApplyGradientDescent\n",
      "train/GradientDescent/update_batch_normalization/beta/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "train/GradientDescent/update_batch_normalization_1/gamma/ApplyGradientDescent\n",
      "train/GradientDescent/update_batch_normalization_1/beta/ApplyGradientDescent\n",
      "train/GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "train/GradientDescent/update_batch_normalization_2/gamma/ApplyGradientDescent\n",
      "train/GradientDescent/update_batch_normalization_2/beta/ApplyGradientDescent\n",
      "train/GradientDescent\n",
      "eval/in_top_k/InTopKV2/k\n",
      "eval/in_top_k/InTopKV2\n",
      "eval/Cast\n",
      "eval/Const\n",
      "eval/accuracy\n",
      "init\n",
      "save/filename/input\n",
      "save/filename\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/Assign_1\n",
      "save/Assign_2\n",
      "save/Assign_3\n",
      "save/Assign_4\n",
      "save/Assign_5\n",
      "save/Assign_6\n",
      "save/Assign_7\n",
      "save/Assign_8\n",
      "save/Assign_9\n",
      "save/Assign_10\n",
      "save/Assign_11\n",
      "save/Assign_12\n",
      "save/Assign_13\n",
      "save/Assign_14\n",
      "save/Assign_15\n",
      "save/Assign_16\n",
      "save/Assign_17\n",
      "save/restore_all\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "   print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "training = tf.get_default_graph().get_tensor_by_name(\"training:0\")\n",
    "\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"train/GradientDescent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Test accuracy: 0.95\n",
      "1 Test accuracy: 0.952\n",
      "2 Test accuracy: 0.9547\n",
      "3 Test accuracy: 0.9573\n",
      "4 Test accuracy: 0.9569\n",
      "5 Test accuracy: 0.9588\n",
      "6 Test accuracy: 0.9601\n",
      "7 Test accuracy: 0.9613\n",
      "8 Test accuracy: 0.9626\n",
      "9 Test accuracy: 0.963\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can then also revise the computational graph...\n",
    "\n",
    "Typically will want to replace the upper layers of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Freezing lower layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The lower layers of the first network have already learnt low-level features for the first task, so they can be reused as they are. \n",
    "\n",
    "That is, freezing their weights so that they are not altered during subsequent training of the new network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can be acheived by providing restricted list of training variables to optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "#                                scope=\"hidden2|outputs\")\n",
    "# training_op = optimizer.minimize(loss, var_list=train_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Caching the frozen layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Since the weights of the frozen layers don't change, their output for a given training instance also does not change.\n",
    "\n",
    "Caching these outputs can provide a considerable computational saving since the entire data-set needs to be processed multiple times.\n",
    "\n",
    "But can result in very large additional storage requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model zoos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Many trained Tensor Flow models are available at \n",
    "[https://github.com/tensorflow/models](https://github.com/tensorflow/models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Improved optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Although standard (stochastic) gradient descent is very effective it can still be slow for deep networks.\n",
    "\n",
    "There are a number of more advanced optimizers that provide improvements, e.g.:\n",
    "- Momentum optimization\n",
    "- Nesterov accelerated gradient\n",
    "- AdaGrad\n",
    "- RMSProp\n",
    "- Adam optimization\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recall gradient descent, with cost function $J(\\theta)$ and gradients $\\nabla_\\theta J(\\theta)$, proceeds simply by updating the weights $\\theta$ by taking a step $\\eta$ (learning rate) in the direction of the gradient:\n",
    "\n",
    "$$\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Momentum optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Momentum optimization uses the gradients to modify a momentum vector and uses the momentum to update the weights:\n",
    "\n",
    "1. $m \\leftarrow \\beta m + \\eta \\nabla_\\theta J(\\theta)$\n",
    "2. $\\theta \\leftarrow \\theta - m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gradient is used as an acceleration rather than speed.  Can help to traverse plateaus and to avoid local minima.\n",
    "\n",
    "The additional hyperparameter $\\beta$ is introduced as a friction term to avoid the momentum growing too large (typically $\\beta \\sim 0.9$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Nesterov accelerated gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Nesterov accelerated gradient is a variant of momentum optimization where the gradient is computed further ahead in the direction of the momentum:\n",
    "\n",
    "1. $m \\leftarrow \\beta m + \\eta \\nabla_\\theta J(\\theta + \\beta m)$\n",
    "2. $\\theta \\leftarrow \\theta - m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In general the momentum will be pointing toward the optimum and so Nesterov modification typically provides an improvement over standard momentum optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "AdaGrad scales down the gradient vector along the steepest direction by incorporating a gradient squared term:\n",
    "\n",
    "1. $s \\leftarrow s + \\nabla_\\theta J(\\theta) \\otimes \\nabla_\\theta J(\\theta)$\n",
    "2. $\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta) \\oslash \\sqrt{s+\\epsilon}$\n",
    "\n",
    "Note that $\\otimes$ and $\\oslash$ are elementwise multiplication and division, respectively.\n",
    "\n",
    "The parameter $\\epsilon$ is introduced for numerical stability (typically $\\epsilon\\sim 10^{-10}$).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Basically, AdaGrad correspondings to an *adaptive learning rate* where the learning rate is decayed faster for steep directions.\n",
    "\n",
    "Consequently, it requires much less tuning of the learning rate $\\eta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"Lecture13_Images/ada_grad.png\" style=\"height: 500px;\"/></center>\n",
    "\n",
    "[Credit: Geron]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "RMSProp extends AdaGrad by introducing an exponential decay in the accumulated squared gradient:\n",
    "\n",
    "1. $s \\leftarrow \\beta s + (1-\\beta) \\nabla_\\theta J(\\theta) \\otimes \\nabla_\\theta J(\\theta)$\n",
    "2. $\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta) \\oslash \\sqrt{s+\\epsilon}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(Typically $\\beta\\sim 0.9$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Avoids the problem where AdaGrad slows down too fast and so doesn't converge to the global optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Adam optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Adam optimization combines momentum and RMSProp:\n",
    "\n",
    "1. $m \\leftarrow \\beta_1 m + (1-\\beta_1) \\nabla_\\theta J(\\theta)$\n",
    "2. $s \\leftarrow \\beta_2 s + (1-\\beta_2) \\nabla_\\theta J(\\theta)\\otimes\\nabla_\\theta J(\\theta)$\n",
    "3. $m \\leftarrow \\frac{m}{1-\\beta_1^{t}}$, where $t$ is the iteration number \n",
    "4. $s \\leftarrow \\frac{s}{1-\\beta_2^{t}}$, where $t$ is the iteration number\n",
    "5. $\\theta \\leftarrow \\theta - \\eta m \\oslash \\sqrt{s+\\epsilon}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Steps 3 and 4 are introduced to boost $m$ and $s$ at the beginnning of training (since they are initialed to 0 they can otherwise be low at the beginning).\n",
    "\n",
    "(Typically $\\beta_1 \\sim 0.9$, $\\beta_2 \\sim 0.999$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Deep networks have many parameters (sometimes millions) and so are prone to overfitting.\n",
    "\n",
    "Regularization therefore becomes increasingly important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A simple regularization strategy is to end training early, e.g. when performance on validation set starts to degrade.\n",
    "\n",
    "Although early stopping works well, other regularisation techniques can lead to better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## $\\ell_2$ and $\\ell_1$ regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "*Tikhonov* regularization adopts $\\ell_2$ regularising term (also called *Ridge regression*):\n",
    "\n",
    "\n",
    "$$ R(\\theta) = \\frac{1}{2} \\sum_{j=1}^n \\theta_j^2 = \\frac{1}{2}  \\theta^{\\rm T}\\theta.$$\n",
    "\n",
    "\n",
    "*Lasso* regularization adopts $\\ell_1$ regularising term:\n",
    "\n",
    "$$ R(\\theta) =\\sum_{j=1}^n \\left\\vert \\theta_j \\right\\vert .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Elastic net* regularization provides a mix of Tikhonov and Lasso regularization, controlled by mix ratio $r$:\n",
    "\n",
    "$$ R(\\theta) =  r\\sum_{j=1}^n \\left\\vert \\theta_j \\right\\vert + \\frac{1-r}{2} \\sum_{j=1}^n \\theta_j^2.$$\n",
    "\n",
    "- For $r=0$, corresponds to Tikhonov regularization.\n",
    "- For $r=1$, corresponds to Lasso regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Dropout is a very popular and effective regularlisation technique developed by [Geoff Hinton in 2012](http://www.jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dropout involves simply dropping each neuron for a given training set with probability $p$.\n",
    "\n",
    "<center><img src=\"Lecture13_Images/dropout.png\" style=\"height: 350px;\"/></center>\n",
    "\n",
    "[Credit: Geron]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Dropout encourages each neuron to be as effective as possible individually and not to rely heavily on a few nearby neurons but to consider all input neurons carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The probability $p$ is called the *dropout rate* (typically $p \\sim 0.5$).\n",
    "\n",
    "After training the neurons don't get dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The number of inputs of active neurons is lower when dropout is applied during training, than when the network is applied during testing.  \n",
    "\n",
    "For example, if $p=0.5$, on average there are half as many input neurons during training than when testing.  During testing each neuron will get an input signal (approximately) twice as large as during training.\n",
    "\n",
    "It is important to account for this difference.\n",
    "\n",
    "To compensate, after training each neurons input weights are multiplied by the keep probability $1-p$ before applying the network to test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Data augmentation can be applied both as a regularization technique and to increase the volume of the training set.\n",
    "\n",
    "Essentially, new training instances are created from the original training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, for images, data augmentation can be performed by rotating, shifting, scaling, flipping, changing the contrast, ..., of the original images in the training data-set.\n",
    "\n",
    "<center><img src=\"Lecture13_Images/data_augmentation.png\" style=\"height: 500px;\"/></center>\n",
    "\n",
    "[Credit: Geron]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Appropriate data augmentation strategies depend on the type of data under consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Typically training instances are generated on the fly to avoid additional storage requirements.  \n",
    "\n",
    "Tensor Flow has built in functionality for many transformations for image data, making data augmentation for image data straightforward."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
